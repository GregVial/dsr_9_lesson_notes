{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7fecea20a5c0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './metastore_db/*.lck': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm ./metastore_db/*.lck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlc = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-02-02 16:47:14--  https://github.com/databricks/spark-csv/raw/master/src/test/resources/cars.csv\n",
      "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
      "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/databricks/spark-csv/master/src/test/resources/cars.csv [following]\n",
      "--2017-02-02 16:47:15--  https://raw.githubusercontent.com/databricks/spark-csv/master/src/test/resources/cars.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.112.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.112.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 134 [text/plain]\n",
      "Saving to: ‘cars.csv’\n",
      "\n",
      "cars.csv            100%[===================>]     134  --.-KB/s    in 0s      \n",
      "\n",
      "2017-02-02 16:47:15 (29.1 MB/s) - ‘cars.csv’ saved [134/134]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/databricks/spark-csv/raw/master/src/test/resources/cars.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cars = sqlc.read.format(\"com.databricks.spark.csv\") \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .option(\"inferSchema\", \"true\") \\\n",
    "                .load(\"cars.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+--------------------+-----+\n",
      "|year| make|model|             comment|blank|\n",
      "+----+-----+-----+--------------------+-----+\n",
      "|2012|Tesla|    S|          No comment|     |\n",
      "|1997| Ford| E350|Go get one now th...|     |\n",
      "|2015|Chevy| Volt|                null| null|\n",
      "+----+-----+-----+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- make: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- comment: string (nullable = true)\n",
      " |-- blank: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "customSchema = StructType([StructField(\"year\", StringType(), True),\n",
    "                           StructField(\"make\", StringType(), True),\n",
    "                           StructField(\"model\", StringType(), True), \n",
    "                           StructField(\"comment\", StringType(), True),\n",
    "                           StructField(\"blank\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cars2 = sqlc.read.load(path=\"cars.csv\", \n",
    "                          format=\"com.databricks.spark.csv\", \n",
    "                          schema=customSchema,\n",
    "                          header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: string (nullable = true)\n",
      " |-- make: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- comment: string (nullable = true)\n",
      " |-- blank: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm -rf newcars.csv\n",
    "\n",
    "selectedData = df_cars.select(\"year\", \"model\",\"comment\")\n",
    "selectedData.coalesce(1).write.format(\"com.databricks.spark.csv\") \\\n",
    "                        .option(\"header\", \"true\") \\\n",
    "                        .option(\"nullValue\",\"NA\") \\\n",
    "                        .save(\"newcars.csv\") \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\r\n",
      "-rw-r--r-- 1 dsi-student dsi-student 95 Feb  2 16:47 part-r-00000-3c303ffa-76ac-453a-a731-a0ec829de174.csv\r\n",
      "-rw-r--r-- 1 dsi-student dsi-student  0 Feb  2 16:47 _SUCCESS\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l newcars.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf newcars.csv.gz\n",
    "selectedData.write.format(\"com.databricks.spark.csv\") \\\n",
    "                    .option(\"header\", \"true\") \\\n",
    "                    .option(\"codec\", \"gzip\") \\\n",
    "                    .save(\"newcars.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\r\n",
      "-rw-r--r-- 1 dsi-student dsi-student 104 Feb  2 16:50 part-r-00000-61ce5cad-fe59-45e3-9543-7a406af8e3e0.csv.gz\r\n",
      "-rw-r--r-- 1 dsi-student dsi-student   0 Feb  2 16:50 _SUCCESS\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l newcars.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-02-02 16:51:52--  https://github.com/databricks/spark-xml/raw/master/src/test/resources/books.xml\n",
      "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
      "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/databricks/spark-xml/master/src/test/resources/books.xml [following]\n",
      "--2017-02-02 16:51:53--  https://raw.githubusercontent.com/databricks/spark-xml/master/src/test/resources/books.xml\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.112.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.112.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5542 (5.4K) [text/plain]\n",
      "Saving to: ‘books.xml’\n",
      "\n",
      "books.xml           100%[===================>]   5.41K  --.-KB/s    in 0.002s  \n",
      "\n",
      "2017-02-02 16:51:53 (2.42 MB/s) - ‘books.xml’ saved [5542/5542]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/databricks/spark-xml/raw/master/src/test/resources/books.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\"?>\r\n",
      "<catalog>\r\n",
      "   <book id=\"bk101\">\r\n",
      "      <author>Gambardella, Matthew</author>\r\n",
      "      <title>XML Developer's Guide</title>\r\n",
      "      <genre>Computer</genre>\r\n",
      "      <price>44.95</price>\r\n",
      "      <publish_date>2000-10-01</publish_date>\r\n",
      "      <description>\r\n",
      "\r\n",
      "\r\n",
      "         An in-depth look at creating applications\r\n",
      "         with XML.This manual describes Oracle XML DB, and how you can use it to store, generate, manipulate, manage,\r\n",
      "         and query XML data in the database.\r\n",
      "\r\n",
      "\r\n",
      "         After introducing you to the heart of Oracle XML DB, namely the XMLType framework and Oracle XML DB repository,\r\n",
      "         the manual provides a brief introduction to design criteria to consider when planning your Oracle XML DB\r\n",
      "         application. It provides examples of how and where you can use Oracle XML DB.\r\n",
      "\r\n",
      "\r\n",
      "         The manual then describes ways you can store and retrieve XML data using Oracle XML DB, APIs for manipulating\r\n",
      "         XMLType data, and ways you can view, generate, transform, and search on existing XML data. The remainder of\r\n",
      "         the manual discusses how to use Oracle XML DB repository, including versioning and security,\r\n",
      "         how to access and manipulate repository resources using protocols, SQL, PL/SQL, or Java, and how to manage\r\n",
      "         your Oracle XML DB application using Oracle Enterprise Manager. It also introduces you to XML messaging and\r\n",
      "         Oracle Streams Advanced Queuing XMLType support.\r\n",
      "      </description></book><book id=\"bk102\">\r\n",
      "      <author>Ralls, Kim</author>\r\n",
      "      <title>Midnight Rain</title>\r\n",
      "      <genre>Fantasy</genre>\r\n",
      "      <price>5.95</price>\r\n",
      "      <publish_date>2000-12-16</publish_date>\r\n",
      "      <description>A former architect battles corporate zombies, \r\n",
      "      an evil sorceress, and her own childhood to become queen \r\n",
      "      of the world.</description>\r\n",
      "   </book>\r\n",
      "   <book id=\"bk103\">\r\n",
      "      <author>Corets, Eva</author>\r\n",
      "      <title>Maeve Ascendant</title>\r\n",
      "      <genre>Fantasy</genre>\r\n",
      "      <price>5.95</price>\r\n",
      "      <publish_date>2000-11-17</publish_date>\r\n",
      "      <description>After the collapse of a nanotechnology \r\n",
      "      society in England, the young survivors lay the \r\n",
      "      foundation for a new society.</description>\r\n",
      "   </book>\r\n",
      "   <book id=\"bk104\">\r\n",
      "      <author>Corets, Eva</author>\r\n",
      "      <title>Oberon's Legacy</title>\r\n",
      "      <genre>Fantasy</genre>\r\n",
      "      <price>5.95</price>\r\n",
      "      <publish_date>2001-03-10</publish_date>\r\n",
      "      <description>In post-apocalypse England, the mysterious \r\n",
      "      agent known only as Oberon helps to create a new life \r\n",
      "      for the inhabitants of London. Sequel to Maeve \r\n",
      "      Ascendant.</description>\r\n",
      "   </book>\r\n",
      "   <book id=\"bk105\">\r\n",
      "      <author>Corets, Eva</author>\r\n",
      "      <title>The Sundered Grail</title>\r\n",
      "      <genre>Fantasy</genre>\r\n",
      "      <price>5.95</price>\r\n",
      "      <publish_date>2001-09-10</publish_date>\r\n",
      "      <description>The two daughters of Maeve, half-sisters, \r\n",
      "      battle one another for control of England. Sequel to \r\n",
      "      Oberon's Legacy.</description>\r\n",
      "   </book>\r\n",
      "   <book id=\"bk106\">\r\n",
      "      <author>Randall, Cynthia</author>\r\n",
      "      <title>Lover Birds</title>\r\n",
      "      <genre>Romance</genre>\r\n",
      "      <price>4.95</price>\r\n",
      "      <publish_date>2000-09-02</publish_date>\r\n",
      "      <description>When Carla meets Paul at an ornithology \r\n",
      "      conference, tempers fly as feathers get ruffled.</description>\r\n",
      "   </book>\r\n",
      "   <book id=\"bk107\">\r\n",
      "      <author>Thurman, Paula</author>\r\n",
      "      <title>Splish Splash</title>\r\n",
      "      <genre>Romance</genre>\r\n",
      "      <price>4.95</price>\r\n",
      "      <publish_date>2000-11-02</publish_date>\r\n",
      "      <description>A deep sea diver finds true love twenty \r\n",
      "      thousand leagues beneath the sea.</description>\r\n",
      "   </book>\r\n",
      "   <book id=\"bk108\">\r\n",
      "      <author>Knorr, Stefan</author>\r\n",
      "      <title>Creepy Crawlies</title>\r\n",
      "      <genre>Horror</genre>\r\n",
      "      <price>4.95</price>\r\n",
      "      <publish_date>2000-12-06</publish_date>\r\n",
      "      <description>An anthology of horror stories about roaches,\r\n",
      "      centipedes, scorpions  and other insects.</description>\r\n",
      "   </book>\r\n",
      "   <book id=\"bk109\">\r\n",
      "      <author>Kress, Peter</author>\r\n",
      "      <title>Paradox Lost</title>\r\n",
      "      <genre>Science Fiction</genre>\r\n",
      "      <price>6.95</price>\r\n",
      "      <publish_date>2000-11-02</publish_date>\r\n",
      "      <description>After an inadvertant trip through a Heisenberg\r\n",
      "      Uncertainty Device, James Salway discovers the problems \r\n",
      "      of being quantum.</description>\r\n",
      "   </book>\r\n",
      "   <book id=\"bk110\">\r\n",
      "      <author>O'Brien, Tim</author>\r\n",
      "      <title>Microsoft .NET: The Programming Bible</title>\r\n",
      "      <genre>Computer</genre>\r\n",
      "      <price>36.95</price>\r\n",
      "      <publish_date>2000-12-09</publish_date>\r\n",
      "      <description>Microsoft's .NET initiative is explored in \r\n",
      "      detail in this deep programmer's reference.</description>\r\n",
      "   </book>\r\n",
      "   <book id=\"bk111\">\r\n",
      "      <author>O'Brien, Tim</author>\r\n",
      "      <title>MSXML3: A Comprehensive Guide</title>\r\n",
      "      <genre>Computer</genre>\r\n",
      "      <price>36.95</price>\r\n",
      "      <publish_date>2000-12-01</publish_date>\r\n",
      "      <description>The Microsoft MSXML3 parser is covered in \r\n",
      "      detail, with attention to XML DOM interfaces, XSLT processing, \r\n",
      "      SAX and more.</description>\r\n",
      "   </book>\r\n",
      "   <book id=\"bk112\">\r\n",
      "      <author>Galos, Mike</author>\r\n",
      "      <title>Visual Studio 7: A Comprehensive Guide</title>\r\n",
      "      <genre>Computer</genre>\r\n",
      "      <price>49.95</price>\r\n",
      "      <publish_date>2001-04-16</publish_date>\r\n",
      "      <description>Microsoft Visual Studio 7 is explored in depth,\r\n",
      "      looking at how Visual Basic, Visual C++, C#, and ASP+ are \r\n",
      "      integrated into a comprehensive development \r\n",
      "      environment.</description>\r\n",
      "   </book>\r\n",
      "</catalog>\r\n"
     ]
    }
   ],
   "source": [
    "!cat books.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_books = sqlc.read.format(\"com.databricks.spark.xml\") \\\n",
    "                    .option(\"rowTag\", \"book\") \\\n",
    "                    .load(\"books.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- publish_date: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_books.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+---------------+-----+------------+--------------------+\n",
      "|  _id|              author|         description|          genre|price|publish_date|               title|\n",
      "+-----+--------------------+--------------------+---------------+-----+------------+--------------------+\n",
      "|bk101|Gambardella, Matthew|\n",
      "\n",
      "\n",
      "         An in...|       Computer|44.95|  2000-10-01|XML Developer's G...|\n",
      "|bk102|          Ralls, Kim|A former architec...|        Fantasy| 5.95|  2000-12-16|       Midnight Rain|\n",
      "|bk103|         Corets, Eva|After the collaps...|        Fantasy| 5.95|  2000-11-17|     Maeve Ascendant|\n",
      "|bk104|         Corets, Eva|In post-apocalyps...|        Fantasy| 5.95|  2001-03-10|     Oberon's Legacy|\n",
      "|bk105|         Corets, Eva|The two daughters...|        Fantasy| 5.95|  2001-09-10|  The Sundered Grail|\n",
      "|bk106|    Randall, Cynthia|When Carla meets ...|        Romance| 4.95|  2000-09-02|         Lover Birds|\n",
      "|bk107|      Thurman, Paula|A deep sea diver ...|        Romance| 4.95|  2000-11-02|       Splish Splash|\n",
      "|bk108|       Knorr, Stefan|An anthology of h...|         Horror| 4.95|  2000-12-06|     Creepy Crawlies|\n",
      "|bk109|        Kress, Peter|After an inadvert...|Science Fiction| 6.95|  2000-11-02|        Paradox Lost|\n",
      "|bk110|        O'Brien, Tim|Microsoft's .NET ...|       Computer|36.95|  2000-12-09|Microsoft .NET: T...|\n",
      "|bk111|        O'Brien, Tim|The Microsoft MSX...|       Computer|36.95|  2000-12-01|MSXML3: A Compreh...|\n",
      "|bk112|         Galos, Mike|Microsoft Visual ...|       Computer|49.95|  2001-04-16|Visual Studio 7: ...|\n",
      "+-----+--------------------+--------------------+---------------+-----+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_books.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm -rf newbooks.xml\n",
    "\n",
    "selectedData = df_books.select(\"author\", \"_id\")\n",
    "selectedData.write.format(\"com.databricks.spark.xml\") \\\n",
    "                .option(\"rootTag\", \"books\") \\\n",
    "                .option(\"rowTag\", \"book\") \\\n",
    "                .save(\"newbooks.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "\n",
    "customSchema = StructType([StructField(\"_id\", StringType(), nullable = True), \n",
    "                           StructField(\"author\", StringType(), nullable = True),\n",
    "                           StructField(\"description\", StringType(), nullable = True),\n",
    "                           StructField(\"genre\", StringType(),nullable = True), \n",
    "                           StructField(\"price\", DoubleType(), nullable = True),\n",
    "                           StructField(\"publish_date\", StringType(), nullable = True),\n",
    "                           StructField(\"title\", StringType(), nullable = True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_books = sqlc.read.format(\"com.databricks.spark.xml\") \\\n",
    "                    .option(\"rowTag\", \"book\") \\\n",
    "                    .schema(customSchema) \\\n",
    "                    .load(\"books.xml\")\n",
    "            \n",
    "selectedData = df_books.select(\"author\", \"_id\")\n",
    "selectedData.write.format(\"com.databricks.spark.xml\") \\\n",
    "                .option(\"rootTag\", \"books\") \\\n",
    "                .option(\"rowTag\", \"book\") \\\n",
    "                .mode(\"overwrite\") \\\n",
    "                .save(\"newbooks.xml\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
