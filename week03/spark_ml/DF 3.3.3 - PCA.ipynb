{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7f6c2ec67790>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm -rf metastore_db/*.lck\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlc = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-09-26 20:07:02--  https://s3.eu-central-1.amazonaws.com/dsr-data/UScrime/UScrime2-colsLotsOfNAremoved.csv\n",
      "Resolving s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)... 54.231.192.53\n",
      "Connecting to s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)|54.231.192.53|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 971758 (949K) [application/octet-stream]\n",
      "Saving to: ‘UScrime2-colsLotsOfNAremoved.csv.2’\n",
      "\n",
      "100%[======================================>] 971.758     3,15MB/s   in 0,3s   \n",
      "\n",
      "2016-09-26 20:07:03 (3,15 MB/s) - ‘UScrime2-colsLotsOfNAremoved.csv.2’ saved [971758/971758]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.eu-central-1.amazonaws.com/dsr-data/UScrime/UScrime2-colsLotsOfNAremoved.csv\n",
    "\n",
    "crimes = sqlc.read.format(\"com.databricks.spark.csv\") \\\n",
    "            .option(\"delimiter\", \",\") \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .option(\"inferSchema\", \"true\") \\\n",
    "            .load(\"UScrime2-colsLotsOfNAremoved.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crimes = crimes.drop(\"OtherPerCap\").drop(\"community\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors, Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler().setInputCols(crimes.columns).setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresDF = assembler.transform(crimes).select(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>pca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.19, 0.33, 0.02, 0.9, 0.12, 0.17, 0.34, 0.47...</td>\n",
       "      <td>[1.2138889197, 0.564567759337, -0.022284837106...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.16, 0.12, 0.74, 0.45, 0.07, 0.26, 0.59...</td>\n",
       "      <td>[0.627985190195, 1.16689414866, -0.51416430664...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 0.42, 0.49, 0.56, 0.17, 0.04, 0.39, 0.47...</td>\n",
       "      <td>[0.234349043189, 0.348070144228, 0.54876884160...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features  \\\n",
       "0  [0.19, 0.33, 0.02, 0.9, 0.12, 0.17, 0.34, 0.47...   \n",
       "1  [0.0, 0.16, 0.12, 0.74, 0.45, 0.07, 0.26, 0.59...   \n",
       "2  [0.0, 0.42, 0.49, 0.56, 0.17, 0.04, 0.39, 0.47...   \n",
       "\n",
       "                                                 pca  \n",
       "0  [1.2138889197, 0.564567759337, -0.022284837106...  \n",
       "1  [0.627985190195, 1.16689414866, -0.51416430664...  \n",
       "2  [0.234349043189, 0.348070144228, 0.54876884160...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "pca = PCA(k=10, inputCol=\"features\", outputCol=\"pca\")\n",
    "\n",
    "model = pca.fit(featuresDF)\n",
    "\n",
    "pc = model.transform(featuresDF)\n",
    "\n",
    "pc.toPandas()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
