{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib \n",
    "matplotlib.use('Agg') \n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## looking at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import array_to_img\n",
    "\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "list_concepts = ['airplane', \n",
    "                 'automobile', \n",
    "                 'bird', \n",
    "                 'cat', \n",
    "                 'deer', \n",
    "                 'dog', \n",
    "                 'frog', \n",
    "                 'horse', \n",
    "                 'ship', \n",
    "                 'truck']\n",
    "\n",
    "nb_classes = len(list_concepts)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49153\n",
      "[2] bird\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAHrElEQVR4nF1WW28dVxVea+09l3Ox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\nRgUirf4XHOPrFey4d5cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x16A305D0C88>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = random.randint(0, len(y_train))\n",
    "print(i,) \n",
    "print(y_train[i], list_concepts[y_train[i][0]])\n",
    "array_to_img(X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import History, ModelCheckpoint\n",
    "\n",
    "class PlotHistory(History):\n",
    "    def __init__(self, file_name='history.png'):\n",
    "        History.__init__(self)\n",
    "        self.file_name = file_name\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        History.on_epoch_end(self, epoch, logs)\n",
    "        self.plot_logs()\n",
    "    def plot_logs(self):\n",
    "        evaluation_cost = self.history['val_loss']\n",
    "        evaluation_accuracy = self.history['val_acc']\n",
    "        training_cost = self.history['loss']\n",
    "        training_accuracy = self.history['acc']\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        f.set_figwidth(10)\n",
    "        ax1.plot(evaluation_cost,label= 'test')\n",
    "        ax1.plot(training_cost, label='train')\n",
    "        ax1.set_title('Cost')\n",
    "        ax1.legend()\n",
    "        ax2.plot(evaluation_accuracy, label='test')\n",
    "        ax2.plot(training_accuracy, label='train')\n",
    "        ax2.set_title('Accuracy')\n",
    "        ax2.legend(loc='lower right')\n",
    "        f.savefig(self.file_name)\n",
    "        plt.close(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "8s - loss: 2.0291 - acc: 0.2730 - val_loss: 1.9512 - val_acc: 0.2811\n",
      "Epoch 2/40\n",
      "6s - loss: 1.8098 - acc: 0.3658 - val_loss: 1.7447 - val_acc: 0.3895\n",
      "Epoch 3/40\n",
      "6s - loss: 1.7210 - acc: 0.3991 - val_loss: 1.6924 - val_acc: 0.4099\n",
      "Epoch 4/40\n",
      "6s - loss: 1.6569 - acc: 0.4215 - val_loss: 1.6137 - val_acc: 0.4428\n",
      "Epoch 5/40\n",
      "6s - loss: 1.6024 - acc: 0.4426 - val_loss: 1.5575 - val_acc: 0.4644\n",
      "Epoch 6/40\n",
      "6s - loss: 1.5609 - acc: 0.4576 - val_loss: 1.5367 - val_acc: 0.4723\n",
      "Epoch 7/40\n",
      "6s - loss: 1.5289 - acc: 0.4677 - val_loss: 1.5376 - val_acc: 0.4511\n",
      "Epoch 8/40\n",
      "6s - loss: 1.4957 - acc: 0.4799 - val_loss: 1.5351 - val_acc: 0.4649\n",
      "Epoch 9/40\n",
      "6s - loss: 1.4696 - acc: 0.4895 - val_loss: 1.5124 - val_acc: 0.4675\n",
      "Epoch 10/40\n",
      "6s - loss: 1.4444 - acc: 0.5007 - val_loss: 1.4542 - val_acc: 0.4926\n",
      "Epoch 11/40\n",
      "6s - loss: 1.4265 - acc: 0.5065 - val_loss: 1.4289 - val_acc: 0.5021\n",
      "Epoch 12/40\n",
      "6s - loss: 1.4048 - acc: 0.5137 - val_loss: 1.4149 - val_acc: 0.5076\n",
      "Epoch 13/40\n",
      "6s - loss: 1.3860 - acc: 0.5224 - val_loss: 1.4593 - val_acc: 0.4896\n",
      "Epoch 14/40\n",
      "6s - loss: 1.3688 - acc: 0.5291 - val_loss: 1.4595 - val_acc: 0.4905\n",
      "Epoch 15/40\n",
      "6s - loss: 1.3528 - acc: 0.5338 - val_loss: 1.3724 - val_acc: 0.5271\n",
      "Epoch 16/40\n",
      "6s - loss: 1.3377 - acc: 0.5388 - val_loss: 1.3626 - val_acc: 0.5306\n",
      "Epoch 17/40\n",
      "6s - loss: 1.3256 - acc: 0.5455 - val_loss: 1.4054 - val_acc: 0.5158\n",
      "Epoch 18/40\n",
      "6s - loss: 1.3037 - acc: 0.5522 - val_loss: 1.3843 - val_acc: 0.5135\n",
      "Epoch 19/40\n",
      "6s - loss: 1.2967 - acc: 0.5538 - val_loss: 1.3385 - val_acc: 0.5369\n",
      "Epoch 20/40\n",
      "6s - loss: 1.2832 - acc: 0.5595 - val_loss: 1.3433 - val_acc: 0.5345\n",
      "Epoch 21/40\n",
      "6s - loss: 1.2668 - acc: 0.5664 - val_loss: 1.3416 - val_acc: 0.5319\n",
      "Epoch 22/40\n",
      "6s - loss: 1.2604 - acc: 0.5683 - val_loss: 1.3476 - val_acc: 0.5357\n",
      "Epoch 23/40\n",
      "6s - loss: 1.2476 - acc: 0.5733 - val_loss: 1.3000 - val_acc: 0.5493\n",
      "Epoch 24/40\n",
      "6s - loss: 1.2319 - acc: 0.5790 - val_loss: 1.2876 - val_acc: 0.5587\n",
      "Epoch 25/40\n",
      "6s - loss: 1.2260 - acc: 0.5804 - val_loss: 1.2685 - val_acc: 0.5594\n",
      "Epoch 26/40\n",
      "6s - loss: 1.2083 - acc: 0.5862 - val_loss: 1.2889 - val_acc: 0.5570\n",
      "Epoch 27/40\n",
      "6s - loss: 1.2004 - acc: 0.5894 - val_loss: 1.2785 - val_acc: 0.5625\n",
      "Epoch 28/40\n",
      "6s - loss: 1.1836 - acc: 0.5958 - val_loss: 1.3613 - val_acc: 0.5324\n",
      "Epoch 29/40\n",
      "6s - loss: 1.1747 - acc: 0.5998 - val_loss: 1.2671 - val_acc: 0.5608\n",
      "Epoch 30/40\n",
      "6s - loss: 1.1604 - acc: 0.6051 - val_loss: 1.2372 - val_acc: 0.5665\n",
      "Epoch 31/40\n",
      "6s - loss: 1.1522 - acc: 0.6086 - val_loss: 1.2424 - val_acc: 0.5686\n",
      "Epoch 32/40\n",
      "6s - loss: 1.1411 - acc: 0.6127 - val_loss: 1.3061 - val_acc: 0.5475\n",
      "Epoch 33/40\n",
      "6s - loss: 1.1307 - acc: 0.6139 - val_loss: 1.2668 - val_acc: 0.5594\n",
      "Epoch 34/40\n",
      "6s - loss: 1.1169 - acc: 0.6175 - val_loss: 1.2680 - val_acc: 0.5659\n",
      "Epoch 35/40\n",
      "6s - loss: 1.1174 - acc: 0.6178 - val_loss: 1.2054 - val_acc: 0.5881\n",
      "Epoch 36/40\n",
      "6s - loss: 1.0972 - acc: 0.6266 - val_loss: 1.2372 - val_acc: 0.5726\n",
      "Epoch 37/40\n",
      "6s - loss: 1.0890 - acc: 0.6287 - val_loss: 1.2573 - val_acc: 0.5649\n",
      "Epoch 38/40\n",
      "6s - loss: 1.0813 - acc: 0.6343 - val_loss: 1.2503 - val_acc: 0.5736\n",
      "Epoch 39/40\n",
      "6s - loss: 1.0750 - acc: 0.6332 - val_loss: 1.2602 - val_acc: 0.5738\n",
      "Epoch 40/40\n",
      "6s - loss: 1.0685 - acc: 0.6380 - val_loss: 1.1961 - val_acc: 0.5828\n",
      "Test score: 1.19612286854\n",
      "Test accuracy: 0.5828\n"
     ]
    }
   ],
   "source": [
    "## magic numbers:\n",
    "batch_size = 128\n",
    "nb_epoch = 40\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                        border_mode='valid',\n",
    "                        input_shape=input_shape))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "plot_history_callback = PlotHistory('cifar10.png')\n",
    "save_snapshots = ModelCheckpoint('cifar10.h5')\n",
    "\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=2, validation_data=(X_test, Y_test), \n",
    "                    callbacks=[plot_history_callback, save_snapshots])\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## looking at our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "import io\n",
    "import numpy\n",
    "def load_photo_from_url(image_url, target_size=None, time_out_image_downloading=1):\n",
    "    response = requests.get(image_url, timeout=time_out_image_downloading)\n",
    "    image = Image.open(io.BytesIO(response.content))\n",
    "    image = image.resize((target_size[1], target_size[0]))\n",
    "    img_array = img_to_array(image) / 255.0\n",
    "    img_array = img_array.reshape((1,) + img_array.shape)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'airplane'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://cdn.eyeem.com/thumb/898895b99f70bff29986de9133516b6a781f5cd0-1437676159/w/450'\n",
    "predictions = model.predict(load_photo_from_url(url,(32,32)))\n",
    "list_concepts[numpy.argmax(predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/50\n",
      "21s - loss: 0.7906 - acc: 0.7332 - val_loss: 0.7449 - val_acc: 0.7457\n",
      "Epoch 2/50\n",
      "18s - loss: 0.6845 - acc: 0.7666 - val_loss: 0.7335 - val_acc: 0.7600\n",
      "Epoch 3/50\n",
      "18s - loss: 0.6500 - acc: 0.7758 - val_loss: 0.6927 - val_acc: 0.7656\n",
      "Epoch 4/50\n",
      "19s - loss: 0.6291 - acc: 0.7818 - val_loss: 0.7201 - val_acc: 0.7625\n",
      "Epoch 5/50\n",
      "18s - loss: 0.6101 - acc: 0.7903 - val_loss: 0.6499 - val_acc: 0.7803\n",
      "Epoch 6/50\n",
      "19s - loss: 0.5987 - acc: 0.7915 - val_loss: 0.6450 - val_acc: 0.7854\n",
      "Epoch 7/50\n",
      "19s - loss: 0.5775 - acc: 0.8001 - val_loss: 0.6468 - val_acc: 0.7860\n",
      "Epoch 8/50\n",
      "22s - loss: 0.5685 - acc: 0.8031 - val_loss: 0.6634 - val_acc: 0.7871\n",
      "Epoch 9/50\n",
      "19s - loss: 0.5523 - acc: 0.8087 - val_loss: 0.6480 - val_acc: 0.7878\n",
      "Epoch 10/50\n",
      "19s - loss: 0.5399 - acc: 0.8129 - val_loss: 0.6488 - val_acc: 0.7821\n",
      "Epoch 11/50\n",
      "19s - loss: 0.5302 - acc: 0.8153 - val_loss: 0.6079 - val_acc: 0.8007\n",
      "Epoch 12/50\n",
      "18s - loss: 0.5211 - acc: 0.8212 - val_loss: 0.6140 - val_acc: 0.7952\n",
      "Epoch 13/50\n",
      "19s - loss: 0.5087 - acc: 0.8245 - val_loss: 0.6103 - val_acc: 0.7984\n",
      "Epoch 14/50\n",
      "19s - loss: 0.4967 - acc: 0.8278 - val_loss: 0.6102 - val_acc: 0.7974\n",
      "Epoch 15/50\n",
      "21s - loss: 0.4892 - acc: 0.8307 - val_loss: 0.6075 - val_acc: 0.7989\n",
      "Epoch 16/50\n",
      "20s - loss: 0.4802 - acc: 0.8341 - val_loss: 0.5806 - val_acc: 0.8122\n",
      "Epoch 17/50\n",
      "19s - loss: 0.4765 - acc: 0.8360 - val_loss: 0.6091 - val_acc: 0.8048\n",
      "Epoch 18/50\n",
      "20s - loss: 0.4646 - acc: 0.8388 - val_loss: 0.5870 - val_acc: 0.8088\n",
      "Epoch 19/50\n",
      "23s - loss: 0.4544 - acc: 0.8437 - val_loss: 0.5896 - val_acc: 0.8106\n",
      "Epoch 20/50\n",
      "19s - loss: 0.4504 - acc: 0.8437 - val_loss: 0.6170 - val_acc: 0.8049\n",
      "Epoch 21/50\n",
      "19s - loss: 0.4391 - acc: 0.8484 - val_loss: 0.6054 - val_acc: 0.8022\n",
      "Epoch 22/50\n",
      "19s - loss: 0.4320 - acc: 0.8509 - val_loss: 0.5913 - val_acc: 0.8100\n",
      "Epoch 23/50\n",
      "18s - loss: 0.4294 - acc: 0.8514 - val_loss: 0.5921 - val_acc: 0.8088\n",
      "Epoch 24/50\n",
      "19s - loss: 0.4276 - acc: 0.8527 - val_loss: 0.6088 - val_acc: 0.8043\n",
      "Epoch 25/50\n",
      "19s - loss: 0.4184 - acc: 0.8551 - val_loss: 0.5833 - val_acc: 0.8177\n",
      "Epoch 26/50\n",
      "19s - loss: 0.4073 - acc: 0.8593 - val_loss: 0.5774 - val_acc: 0.8128\n",
      "Epoch 27/50\n",
      "19s - loss: 0.4101 - acc: 0.8570 - val_loss: 0.5829 - val_acc: 0.8174\n",
      "Epoch 28/50\n",
      "19s - loss: 0.4075 - acc: 0.8585 - val_loss: 0.5941 - val_acc: 0.8102\n",
      "Epoch 29/50\n",
      "19s - loss: 0.4003 - acc: 0.8608 - val_loss: 0.5798 - val_acc: 0.8098\n",
      "Epoch 30/50\n",
      "21s - loss: 0.3955 - acc: 0.8628 - val_loss: 0.5851 - val_acc: 0.8134\n",
      "Epoch 31/50\n",
      "20s - loss: 0.3870 - acc: 0.8648 - val_loss: 0.6113 - val_acc: 0.8123\n",
      "Epoch 32/50\n",
      "20s - loss: 0.3851 - acc: 0.8668 - val_loss: 0.5815 - val_acc: 0.8171\n",
      "Epoch 33/50\n",
      "19s - loss: 0.3722 - acc: 0.8729 - val_loss: 0.5774 - val_acc: 0.8162\n",
      "Epoch 34/50\n",
      "18s - loss: 0.3741 - acc: 0.8702 - val_loss: 0.5713 - val_acc: 0.8207\n",
      "Epoch 35/50\n",
      "19s - loss: 0.3763 - acc: 0.8701 - val_loss: 0.5882 - val_acc: 0.8192\n",
      "Epoch 36/50\n",
      "19s - loss: 0.3653 - acc: 0.8745 - val_loss: 0.5944 - val_acc: 0.8135\n",
      "Epoch 37/50\n",
      "21s - loss: 0.3601 - acc: 0.8755 - val_loss: 0.6203 - val_acc: 0.8020\n",
      "Epoch 38/50\n",
      "19s - loss: 0.3600 - acc: 0.8743 - val_loss: 0.6188 - val_acc: 0.8138\n",
      "Epoch 39/50\n",
      "19s - loss: 0.3584 - acc: 0.8768 - val_loss: 0.5865 - val_acc: 0.8228\n",
      "Epoch 40/50\n",
      "18s - loss: 0.3511 - acc: 0.8791 - val_loss: 0.5887 - val_acc: 0.8220\n",
      "Epoch 41/50\n",
      "20s - loss: 0.3491 - acc: 0.8797 - val_loss: 0.5765 - val_acc: 0.8199\n",
      "Epoch 42/50\n",
      "18s - loss: 0.3459 - acc: 0.8805 - val_loss: 0.6101 - val_acc: 0.8214\n",
      "Epoch 43/50\n",
      "19s - loss: 0.3479 - acc: 0.8793 - val_loss: 0.5777 - val_acc: 0.8206\n",
      "Epoch 44/50\n",
      "19s - loss: 0.3313 - acc: 0.8844 - val_loss: 0.5849 - val_acc: 0.8254\n",
      "Epoch 45/50\n",
      "18s - loss: 0.3387 - acc: 0.8823 - val_loss: 0.6214 - val_acc: 0.8159\n",
      "Epoch 46/50\n",
      "19s - loss: 0.3333 - acc: 0.8865 - val_loss: 0.6226 - val_acc: 0.8240\n",
      "Epoch 47/50\n",
      "20s - loss: 0.3339 - acc: 0.8855 - val_loss: 0.5993 - val_acc: 0.8196\n",
      "Epoch 48/50\n",
      "19s - loss: 0.3288 - acc: 0.8866 - val_loss: 0.6016 - val_acc: 0.8187\n",
      "Epoch 49/50\n",
      "18s - loss: 0.3251 - acc: 0.8871 - val_loss: 0.6209 - val_acc: 0.8139\n",
      "Epoch 50/50\n",
      "18s - loss: 0.3288 - acc: 0.8860 - val_loss: 0.5985 - val_acc: 0.8194\n",
      "Test score: 0.598488698798\n",
      "Test accuracy: 0.8194\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "## magic numbers:\n",
    "batch_size = 128\n",
    "nb_epoch = 50\n",
    "\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "model_ = Sequential()                                                          \n",
    "                                                                               \n",
    "model_.add(Convolution2D(64, kernel_size[0], kernel_size[1],           \n",
    "                            border_mode='valid',                               \n",
    "                            input_shape=input_shape))    \n",
    "model_.add(Activation('relu')) \n",
    "model_.add(Convolution2D(64, kernel_size[0], kernel_size[1],border_mode='same'))          \n",
    "model_.add(Activation('relu'))                       \n",
    "model_.add(MaxPooling2D(pool_size=pool_size))     \n",
    "model_.add(Dropout(0.3))\n",
    "\n",
    "  \n",
    "model_.add(Convolution2D(128, kernel_size[0], kernel_size[1],border_mode='same'))          \n",
    "model_.add(Activation('relu'))                       \n",
    "model_.add(MaxPooling2D(pool_size=pool_size))                                  \n",
    "model_.add(Dropout(0.4))  \n",
    "\n",
    "model_.add(Convolution2D(256, kernel_size[0], kernel_size[1],border_mode='same'))          \n",
    "model_.add(Activation('relu')) \n",
    "model_.add(MaxPooling2D(pool_size=pool_size))                                  \n",
    "model_.add(Dropout(0.4)) \n",
    "\n",
    "model_.add(Convolution2D(512, kernel_size[0], kernel_size[1],border_mode='same'))          \n",
    "model_.add(Activation('relu')) \n",
    "model_.add(MaxPooling2D(pool_size=pool_size))                                  \n",
    "model_.add(Dropout(0.4))\n",
    "\n",
    "model_.add(Flatten())                                                            \n",
    "model_.add(Dense(512))                                                         \n",
    "model_.add(Activation('relu'))   \n",
    "model_.add(Dropout(0.5))\n",
    "\n",
    "model_.add(Dense(256))                                                         \n",
    "model_.add(Activation('relu'))    \n",
    "                                                                                                          \n",
    "model_.add(Dense(nb_classes))                                                  \n",
    "model_.add(Activation('softmax'))                                              \n",
    "                                                                               \n",
    "model_.compile(loss='categorical_crossentropy',                                \n",
    "                      optimizer='Nadam',                                   \n",
    "                      metrics=['accuracy'])  \n",
    "\n",
    "plot_history_callback = PlotHistory('cifar10.png')\n",
    "save_snapshots = ModelCheckpoint('cifar10.h5')\n",
    "\n",
    "print('Using real-time data augmentation.')\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    samples_per_epoch=X_train.shape[0],\n",
    "                    nb_epoch=nb_epoch,\n",
    "validation_data=(X_test, Y_test), verbose=2)\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='same',\n",
    "                        input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "\n",
    "print('Using real-time data augmentation.')\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    samples_per_epoch=X_train.shape[0],\n",
    "                    nb_epoch=nb_epoch,\n",
    "validation_data=(X_test, Y_test), verbose=2)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
