{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "- Process huge datasets in batch \n",
    "- Online (streaming) algorithms that run in little memory\n",
    "- Approximate answers must be good enough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical tasks\n",
    "\n",
    "- approximate counts\n",
    "- approximate count distinct\n",
    "- approximate membership in sets\n",
    "- approximate intersection of sets (e.g. Jaccard Similarity)\n",
    "- approximate nearest neighbor\n",
    "- machine learning: fitting regressions with extremely large number of features\n",
    "- multiplying huge matrices (approximately)\n",
    "- large scale Singular Value Decomposition\n",
    "- approximate numeric histograms\n",
    "- approximate \"heavy hitters\" (most frequent items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash tables\n",
    "\n",
    "Many of those algorithms are related to hash tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 1\n",
    "\n",
    "Specify the interface of a hash table (write a class with methods without implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class myHash:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def getHash(self,hash):\n",
    "        pass\n",
    "\n",
    "    def addHash(self,hash,el):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 2\n",
    "\n",
    "Fill-in the implementation of a hash table. The hash table will not store more than 1024 unique elements. Use lists of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', 'world'), ('Bonjour', 'monde'), ('Hola', 'mundo')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HashTable(object):\n",
    "    def __init__(self, memorysize=1024):\n",
    "        self._size = memorysize\n",
    "        self._bucket = [[] for _ in range(self._size)]\n",
    "        self._keys = []\n",
    "\n",
    "    def get(self, key):\n",
    "        i = self._get_index(key)\n",
    "        for listy in self._bucket[i]:\n",
    "            if listy[0] == key:\n",
    "                return listy[1]\n",
    "    \n",
    "    def put(self, key, value):\n",
    "        assert (not key in self._keys), \"This key already exists in table\"\n",
    "        i = self._get_index(key)\n",
    "        self._bucket[i].append([key,value])\n",
    "        self._keys.append(key)\n",
    "    \n",
    "    def items(self):\n",
    "        return [(key, self.get(key)) for key in self._keys]\n",
    "    \n",
    "    def _get_index(self, key):\n",
    "        assert isinstance(key, str), \"This implementation only accepts strings as keys\"\n",
    "        return hash(key) % self._size\n",
    "    \n",
    "# Table that collides\n",
    "table = HashTable(memorysize=2)\n",
    "table.put('Hello', \"world\")\n",
    "table.put('Bonjour', \"monde\")\n",
    "table.put('Hola', \"mundo\")\n",
    "table.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Excercise 3\n",
    "\n",
    "Explore collections.defaultdict to count (key,values). Can you use a counter.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "dd = defaultdict(list)\n",
    "for k,v in table.items():\n",
    "    dd[k].append(v)\n",
    "len(list(dd.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 4\n",
    "Count the number of distinct objects in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object seq_of_random_strings at 0x7f59904b0e08>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Based on http://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python\n",
    "import string\n",
    "import random\n",
    "def random_string(size=20, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))\n",
    "\n",
    "def seq_of_random_strings(n):\n",
    "    for i in range(0, n):\n",
    "        yield random_string()\n",
    "    \n",
    "random_strings = seq_of_random_strings(1000)\n",
    "random_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB20387W6RJ36U13W7C4\n",
      "L6BMWPI3TG80LOWGC1ZZ\n",
      "3SRXQBZKVX38IDK9306L\n",
      "1L411U55JP8ACYACSLJJ\n",
      "DPIMR7IOVFU0KXGDBTOL\n",
      "NH7P1GGRSH9DZ8ETDU4A\n",
      "OO6T3UI96M2IA70Q63F9\n",
      "Z4FL5RCY902V4BJNQR7N\n",
      "F2AB2BMAVUV9I6VZPRZO\n",
      "47YDTH8JXLGW8X60X3YC\n",
      "989\n"
     ]
    }
   ],
   "source": [
    "for i,s in enumerate(random_strings):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print(s)\n",
    "    \n",
    "print(len(set(random_strings)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accurate but very resource consuming as the lists grows\n",
    "random_strings = seq_of_random_strings(10**6)\n",
    "len(set(random_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hyperloglog\n",
    "hll = hyperloglog.HyperLogLog(0.01)\n",
    "\n",
    "random_strings = seq_of_random_strings(10**6)\n",
    "for s in random_strings:\n",
    "    hll.add(s)\n",
    "\n",
    "#print(len(hll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995169\n",
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 6.9 ms\n"
     ]
    }
   ],
   "source": [
    "%time print(len(hll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 5\n",
    "\n",
    "Put the random strings in a Spark dataframe. Make sure to save and reload the Spark Dataframe.\n",
    "\n",
    "- Use count distinct to count the number of unique strings\n",
    "- Use count approx distinct to count the number of unique strings\n",
    "- Report how much time and memory each of the methods took\n",
    "- How different are the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hyperloglog\n",
    "hll = hyperloglog.HyperLogLog(0.01)  # accept 1% counting error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    }
   ],
   "source": [
    "for item in random_strings:\n",
    "    hll.add(item)\n",
    "print len(hll)  # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9989 10006\n",
      "union 15021\n",
      "interesection 4974\n"
     ]
    }
   ],
   "source": [
    "def hllItems(items):\n",
    "    hll = hyperloglog.HyperLogLog(0.01)  # accept 1% counting error\n",
    "    for item in items:\n",
    "        hll.add(item)\n",
    "    return hll\n",
    "\n",
    "set1 = [str(i) for i in range(0, 10000)]\n",
    "\n",
    "set2 = [str(i) for i in range(5000, 15000)]\n",
    "\n",
    "#unionSize = hllItems(set1 + set2)\n",
    "#print len(unionSize)\n",
    "\n",
    "hllS1 = hllItems(set1)\n",
    "szS1 = len(hllS1)\n",
    "\n",
    "\n",
    "hllS2 = hllItems(set2)\n",
    "szS2 = len(hllS2)\n",
    "print szS1, szS2\n",
    "\n",
    "\n",
    "hllS1.update(hllS2) #equivalent to hllItems(set1 + set2)\n",
    "print 'union', len(hllS1)\n",
    "print 'interesection', szS1 + szS2 - len(hllS1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 6\n",
    "\n",
    "Generate a dataset of key-value pairs and put it into a Spark dataframe.\n",
    "For each unique key, count the number of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object random_key_values at 0x7f82a01f3190>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_keys = list(seq_of_random_strings(1000))\n",
    "random_values = list(seq_of_random_strings(100000))\n",
    "\n",
    "def random_key_values(n):\n",
    "    for i in xrange(0, n):\n",
    "        random_key = random.choice(random_keys)\n",
    "        random_value = random.choice(random_values)\n",
    "        yield random_key, random_value\n",
    "\n",
    "random_key_values(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The HyperLogLog Algorithm\n",
    "\n",
    "- Show slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7\n",
    "\n",
    "Find out which of the following database systems implements approximate counting via HyperLogLog or HyperLogLogPlusPlus\n",
    "\n",
    "- Elasticsearch\n",
    "- Redis\n",
    "- Redshift\n",
    "- MongoDB\n",
    "- MySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bloom Filters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8\n",
    "\n",
    "You have a file with longs from 1 to 100000000. However, about 10000 numbers are missing from this list.\n",
    "If each long takes 64 bits the file is about 800 MBs. \n",
    "Can you figure out the missing numbers by reading the file only once and using less than 15 MB.\n",
    "\n",
    "(Imagine you are using something like bitstring.BitArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "input = [8,7,1,3,9]\n",
    "array = [False] * 10\n",
    "for v in input:\n",
    "    array[v] = True\n",
    "for i in range(1,10):\n",
    "    if array[i] == False:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 104\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getsizeof(array), sys.getsizeof(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If implemented with bit array, the array size will be 64 times smaller than the input size containing longs\n",
    "from bitstring import BitArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "class BloomFilter:\n",
    "    def __init__(self, size):\n",
    "        self.store = [0]*size\n",
    "        self.size = size\n",
    "        self.num_coll = 0\n",
    "    \n",
    "    def hashes(self, key):\n",
    "        h1 = hash(key) % self.size\n",
    "        h2 = hash((1 + key)*13) % self.size\n",
    "        return (h1, h2)\n",
    "    \n",
    "   \n",
    "    def add(self, key):\n",
    "        h1, h2 = self.hashes(key)\n",
    "        #if self.store[h1] == 1:\n",
    "        #    print 'collision 1'\n",
    "        #if self.store[h2] == 1:\n",
    "        #    print 'collision 2' \n",
    "        if self.store[h1] == 1 and self.store[h2] == 1:\n",
    "            #print 'collision 1/2'\n",
    "            self.num_coll += 1\n",
    "        self.store[h1] = 1\n",
    "        self.store[h2] = 1\n",
    "        pass\n",
    "    \n",
    "    def exists(self,key):\n",
    "        h1, h2 = self.hashes(key)\n",
    "        return self.store[h1] == 1 and self.store[h2] == 1\n",
    "    \n",
    "b = BloomFilter(4000)\n",
    "for i in reversed(range(0, 1000)):\n",
    "    b.add(i)\n",
    "    \n",
    "b.exists(777)\n",
    "print b.num_coll\n",
    "print b.exists(777)\n",
    "print b.exists(7777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9\n",
    "\n",
    "You have 100000000 strings. A string represents a tuple (user_id, page_id), but this is not important.\n",
    "You want to design a store such that supports:\n",
    "    \n",
    "    - check if a (user_id, page_id) is in the store\n",
    "    - add a (user_id,page_id) to the store\n",
    "    - use very little memory (i.e. bit arrays)\n",
    "    - in 1 out 100 cases the data structure is allowed to report falsely that (user_id, page_id) is in the store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collisions 11.77 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.739899999999999"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version with 2 hash function\n",
    "\n",
    "from bitstring import BitArray\n",
    "big_number = 10**4\n",
    "factor = 8\n",
    "random_strings = seq_of_random_strings(big_number)\n",
    "ba = BitArray(length = big_number*factor)\n",
    "ba.set(0)\n",
    "\n",
    "# Used to store some of the strings to test the algorithm\n",
    "some_strings=[]\n",
    "\n",
    "# Populate the bit arrays\n",
    "for c,s in enumerate(random_strings):\n",
    "    i = hash(s) % (big_number * factor)\n",
    "    ba[i] = True   \n",
    "    if c % (big_number/10) == 0:\n",
    "        some_strings.append(s)\n",
    " \n",
    "# Check collisions\n",
    "random_strings2 = seq_of_random_strings(big_number)\n",
    "res = []\n",
    "for s in random_strings2:\n",
    "    s = s+\"a\"\n",
    "    i = hash(s) % (big_number * factor)\n",
    "    res.append(ba[i])\n",
    "\n",
    "print(\"Collisions %.2f \" % (100*sum(res)/big_number))\n",
    "\n",
    "# Check collisions (100 times)\n",
    "ress = []\n",
    "for _ in range(10**2):\n",
    "    random_strings2 = seq_of_random_strings(big_number)\n",
    "    res = []\n",
    "    for s in random_strings2:\n",
    "        s = s+\"a\"\n",
    "        i = hash(s) % (big_number * factor)\n",
    "        res.append(ba[i])\n",
    "    ress.append(np.mean(100*sum(res)/big_number))\n",
    "np.mean(ress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collisions 4.79 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.8856000000000002"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version with 2 hash functions\n",
    "\n",
    "from bitstring import BitArray\n",
    "big_number = 10**4\n",
    "factor = 4\n",
    "salt = \"DSR\" # Used to change the hash function\n",
    "\n",
    "random_strings = seq_of_random_strings(big_number)\n",
    "ba1 = BitArray(length = big_number*factor)\n",
    "ba1.set(0)\n",
    "ba2 = BitArray(length = big_number*factor)\n",
    "ba2.set(0)\n",
    "\n",
    "# Used to store some of the strings to test the algorithm\n",
    "some_strings=[]\n",
    "\n",
    "# Populate the bit arrays\n",
    "for c,s in enumerate(random_strings):\n",
    "    i = hash(s) % (big_number * factor)\n",
    "    j = hash(s+salt) % (big_number *factor)\n",
    "    ba1[i] = True \n",
    "    ba2[j] = True\n",
    "    if c % (big_number/10) == 0:\n",
    "        some_strings.append(s)\n",
    "\n",
    "# Check collisions (1 trial)\n",
    "random_strings2 = seq_of_random_strings(big_number)\n",
    "res = []\n",
    "for s in random_strings2:\n",
    "    s = s+\"a\"\n",
    "    i = hash(s) % (big_number * factor)\n",
    "    j = hash(s+salt) % (big_number * factor )\n",
    "    res.append(ba1[i] & ba2[j])\n",
    "\n",
    "print(\"Collisions %.2f \" % (100*sum(res)/big_number))\n",
    "\n",
    "# Check collisions (100 trials)\n",
    "ress = []\n",
    "for _ in range(10**2):\n",
    "    random_strings2 = seq_of_random_strings(big_number)\n",
    "    res = []\n",
    "    for s in random_strings2:\n",
    "        s = s+\"a\"\n",
    "        i = hash(s) % (big_number * factor)\n",
    "        j = hash(s+salt) % (big_number * factor )\n",
    "        res.append(ba[i] & ba[j])\n",
    "    ress.append(np.mean(100*sum(res)/big_number))\n",
    "np.mean(ress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collisions 4.98 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.8587999999999996"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version with 2 hash functions but only 1 array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from bitstring import BitArray\n",
    "big_number = 10**4\n",
    "factor = 8\n",
    "salt = \"DSR\" # Used to change the hash function\n",
    "\n",
    "random_strings = seq_of_random_strings(big_number)\n",
    "ba = BitArray(length = big_number*factor)\n",
    "ba.set(0)\n",
    "\n",
    "# Used to store some of the strings to test the algorithm\n",
    "some_strings=[]\n",
    "\n",
    "# Populate the bit arrays\n",
    "for c,s in enumerate(random_strings):\n",
    "    i = hash(s) % (big_number * factor)\n",
    "    j = hash(s+salt) % (big_number *factor)\n",
    "    ba[i] = True \n",
    "    ba[j] = True\n",
    "    if c % (big_number/10) == 0:\n",
    "        some_strings.append(s)\n",
    "\n",
    "# Check collisions (1 trial)\n",
    "random_strings2 = seq_of_random_strings(big_number)\n",
    "res = []\n",
    "for s in random_strings2:\n",
    "    s = s+\"a\"\n",
    "    i = hash(s) % (big_number * factor)\n",
    "    j = hash(s+salt) % (big_number * factor )\n",
    "    res.append(ba[i] & ba[j])\n",
    "\n",
    "print(\"Collisions %.2f \" % (100*sum(res)/big_number))\n",
    "        \n",
    "# Check collisions (100 trials)\n",
    "ress = []\n",
    "for _ in range(10**2):\n",
    "    random_strings2 = seq_of_random_strings(big_number)\n",
    "    res = []\n",
    "    for s in random_strings2:\n",
    "        s = s+\"a\"\n",
    "        i = hash(s) % (big_number * factor)\n",
    "        j = hash(s+salt) % (big_number * factor )\n",
    "        res.append(ba[i] & ba[j])\n",
    "    ress.append(np.mean(100*sum(res)/big_number))\n",
    "np.mean(ress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 10\n",
    "\n",
    "Add the data random_strings from Excercise 4 to a BloomFilter\n",
    "- check if each of the strings is correctly reported to be in the Bloom filter\n",
    "- find a string on which the Bloom Filter makes a mistake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 11\n",
    "\n",
    "Generate two huge random datasets (based on random_strings). Store them in dataframes saved on disk.\n",
    "- Use inner join in Spark to find the elements in both dataframes\n",
    "- Use bloom filters in Spark to find the elements in both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 12\n",
    "\n",
    "Same as excercise 11, but use HyperLogLog to find only the intersection size of the inner join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 13\n",
    "\n",
    "Implement a function that shuffles a list of items (like random.shuffle) calls to random.randint(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 14\n",
    "\n",
    "Implement sampling on streams. This is called reservoir sampling. See below for the interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReservoirSampling:\n",
    "    def __init__(self, k):\n",
    "        \"\"\"\n",
    "            k: number of sample the \n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        \n",
    "    def maybe_add(self, value):\n",
    "        \"\"\"\n",
    "            Add a value to the sample\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def current_sample(self):\n",
    "        \"\"\"\n",
    "            returns the current sample\n",
    "        \"\"\"\n",
    "        pass    \n",
    "    \n",
    "    def merge(self, other):\n",
    "        \"\"\"\n",
    "            merges two samples\n",
    "            don't implement it here\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 15\n",
    "\n",
    "You have a stream of records (e.g. requests to web services) that have a value associated with them (e.g. latency).\n",
    "The requests are streamed to a service that has to keep K (e.g. 1000) requests from the last day that have had highest latency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
