{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/*@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "}\n",
       "@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tfont-weight: bold;\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "}\n",
       "@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tfont-style: oblique;\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "}\n",
       "@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tfont-weight: bold;\n",
       "\tfont-style: oblique;\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "}*/\n",
       "\n",
       ".navbar-brand, .current_kernel_logo {display:none}\n",
       ".container {\n",
       "    width:80%;    \n",
       "}\n",
       "\n",
       "h1 {\n",
       "\tfont-family: Helvetica, serif;\n",
       "}\n",
       "h4{\n",
       "\tmargin-top:12px;\n",
       "\tmargin-bottom: 3px;\n",
       "   }\n",
       "div.text_cell_render{\n",
       "\tfont-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "\tline-height: 145%;\n",
       "\tfont-size: 100%;\n",
       "\twidth:100%;\n",
       "\tmargin-left:auto;\n",
       "\tmargin-right:auto;\n",
       "}\n",
       ".CodeMirror{\n",
       "\t\tfont-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "}\n",
       ".text_cell_render h5 {\n",
       "\tfont-weight: 300;\n",
       "\tfont-size: 22pt;\n",
       "\t/*color: #4057A1;*/\n",
       "\tfont-style: italic;\n",
       "\tmargin-bottom: .5em;\n",
       "\tmargin-top: 0.5em;\n",
       "\tdisplay: block;\n",
       "}\n",
       "\n",
       ".warning{\n",
       "\tcolor: rgb( 240, 20, 20 )\n",
       "\t}   \n",
       "\n",
       "div.spoiler {\n",
       "\tdisplay: none;\n",
       "}\n",
       "\n",
       ".rendered_html code {\n",
       "\tborder: 0;\n",
       "\t/*background-color: #eee;*/\n",
       "\tfont-size: 100%;\n",
       "\tpadding: 1px 2px;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import css_from_file\n",
    "css_from_file('style/style.css')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape (3751, 1776)\n",
      "testing data shape (2501, 1776)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def load(path):\n",
    "    df = pd.read_csv(path)\n",
    "    if \"Activity\" not in df.columns:\n",
    "        df[\"Activity\"] = np.nan\n",
    "    return df.drop(\"Activity\",axis=1), df.Activity\n",
    "    \n",
    "X_tr, y_tr = load(\"data/boehringer/train.csv\")\n",
    "X_te, y_te = load(\"data/boehringer/test.csv\")\n",
    "\n",
    "print(\"training data shape\", X_tr.shape)\n",
    "print(\"testing data shape\", X_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise\n",
    "----------------\n",
    "\n",
    "Using your knowledge from 2.1 try to combine many models into a single solution.\n",
    "The simplest way to do this is to use `sklearn.ensemble.VotingClassifier`.\n",
    "\n",
    "1. Read the documentation http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier\n",
    "\n",
    "2. Which method is better for voting (`hard` or `soft`)? Why?\n",
    "\n",
    "3. Use more than 3 different algorithms. Check their performance separately and using VotingClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf\n",
      "Your error is 0.442813586654\n",
      "gbm\n",
      "Your error is 0.478147807518\n",
      "et\n",
      "Your error is 0.519231127932\n",
      "bag\n",
      "Your error is 0.482395310289\n",
      "svm\n",
      "Your error is 0.475816755304\n",
      "voting\n",
      "Your error is 0.446862440071\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from cross_validation import cross_val_apply\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "clfs = [\n",
    "    ('rf',RandomForestClassifier(n_estimators=300,n_jobs=1, criterion = 'entropy', max_depth = 50,\n",
    "                                max_features = 350, random_state = 123)),\n",
    "    ('gbm',GradientBoostingClassifier()),\n",
    "    ('et',ExtraTreesClassifier(n_estimators=100,n_jobs=1)),\n",
    "    ('bag', BaggingClassifier(n_estimators=100)),\n",
    "    ('svm', make_pipeline(StandardScaler(), SVC(probability=True)))\n",
    "]\n",
    "\n",
    "voting_clf = ('voting',VotingClassifier(estimators=clfs,voting='soft'))\n",
    "\n",
    "for clf_name, clf in clfs + [voting_clf]:\n",
    "    print(clf_name)\n",
    "    oof_predictions = cross_val_apply(clf, X_tr, y_tr, cv=4,\n",
    "                                      n_jobs=-1, decision_func=\"predict_proba\")\n",
    "\n",
    "    err = log_loss(y_tr, oof_predictions)\n",
    "    print(\"Your error is\", err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Double click to see the answers\n",
    "\n",
    "<div class=\"spoiler\">\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from cross_validation import cross_val_apply\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clfs = [\n",
    "    ('rf',RandomForestClassifier(n_estimators=100,n_jobs=1)),\n",
    "    ('gbm',GradientBoostingClassifier()),\n",
    "    ('et',ExtraTreesClassifier(n_estimators=100,n_jobs=1)),\n",
    "    ('xgb', XGBClassifier()),\n",
    "    ('bag', BaggingClassifier(n_estimators=100)),\n",
    "    ('svm', make_pipeline(StandardScaler(), SVC(probability=True)))\n",
    "]\n",
    "\n",
    "voting_clf = ('voting',VotingClassifier(estimators=clfs,voting='soft'))\n",
    "\n",
    "for clf_name, clf in clfs + [voting_clf]:\n",
    "    print(clf_name)\n",
    "    oof_predictions = cross_val_apply(clf, X_tr, y_tr, cv=4,\n",
    "                                      n_jobs=-1, decision_func=\"predict_proba\")\n",
    "\n",
    "    err = log_loss(y_tr, oof_predictions)\n",
    "    print(\"Your error is\", err)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_forest = BaggingClassifier(make_pipeline(\n",
    "                        make_union(RandomTreesEmbedding(n_estimators=10), \n",
    "                                   LazyTransformer()),\n",
    "                        StandardScaler(with_mean=False), \n",
    "                        VarianceThreshold(0.001),\n",
    "                        MLPClassifier((25,), alpha=10.0, verbose=False)), \n",
    "                        max_samples=0.75,\n",
    "                        max_features=0.75,\n",
    "                        n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
