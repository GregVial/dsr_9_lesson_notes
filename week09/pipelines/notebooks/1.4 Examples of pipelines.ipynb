{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Production examples of a model\n",
    "---------------------------\n",
    "\n",
    "1.\n",
    "\n",
    "```python\n",
    "\n",
    "from string import lower\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "\n",
    "from some_library import ChangeCounter, TextStats, LanguageModelScore\n",
    "from some_library import (ApplyFunction, MissingValuesFiller,\n",
    "                          PandasSelector, make_pandas_categorical_vectorizer)\n",
    "from some_library import Densify\n",
    "\n",
    "\"\"\"\n",
    "Data preparation and validation:\n",
    "1. Put selector as a first transformer to make meaningful errors during\n",
    "   calling\n",
    "2. Fill missing values\n",
    "3. Convert src_lang and dst_lang to lowercase\n",
    "\n",
    "Features:\n",
    "1. Character ngrams of src_text and dst_text\n",
    "2. Word ngrams (with high frequency) of src_text and dst_text\n",
    "3. TextStats - many different measures to compare src_text and dst_text\n",
    "4. One hot encoding of categorical features: src_lang, dst_lang, category\n",
    "\n",
    "Model:\n",
    "1. RandomForestsClassifier\n",
    "\"\"\"\n",
    "\n",
    "classifier = make_pipeline(\n",
    "    PandasSelector(columns=['category', 'src_lang', 'dst_lang',\n",
    "                            'src_text', 'dst_text']),\n",
    "    MissingValuesFiller(),\n",
    "    ApplyFunction(columns=['src_lang', 'dst_lang'], fun=lower),\n",
    "\n",
    "    # here we start adding features\n",
    "    make_union(\n",
    "        make_pipeline(\n",
    "            PandasSelector(columns=['src_text']),\n",
    "            CountVectorizer(analyzer='char',\n",
    "                            ngram_range=(1, 1),\n",
    "                            min_df=10)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            PandasSelector(columns=['dst_text']),\n",
    "            CountVectorizer(analyzer='char',\n",
    "                            ngram_range=(1, 1),\n",
    "                            min_df=10)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            PandasSelector(columns=['src_text']),\n",
    "            CountVectorizer(analyzer='word',\n",
    "                            ngram_range=(1, 1),\n",
    "                            min_df=25)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            PandasSelector(columns=['dst_text']),\n",
    "            CountVectorizer(analyzer='word',\n",
    "                            ngram_range=(1, 1),\n",
    "                            min_df=25)\n",
    "        ),\n",
    "        make_pandas_categorical_vectorizer(\n",
    "            columns=['src_lang', 'dst_lang', 'category']\n",
    "        ),\n",
    "        TextStats()\n",
    "    ),\n",
    "\n",
    "    # densify makes RandomForestClassifier much faster\n",
    "    Densify(),\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        n_jobs=-1,\n",
    "        min_samples_split=20, min_samples_leaf=10,\n",
    "        verbose=True,\n",
    "        random_state=1)\n",
    ")```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Simpler one\n",
    "---------------\n",
    "\n",
    "```python\n",
    "model_pipeline = make_pipeline(\n",
    "    PandasSelector(columns=['prospect_details']),\n",
    "    MapTransformer(func=clean_text_from_object, n_jobs=6),\n",
    "    MapTransformer(func=JSONFeatureExtractor(prefix=[\"prospect_details\"], string_processors=[YearMonthProcessor()]), n_jobs=6),\n",
    "    DictVectorizer(),\n",
    "    ColumnSparsityFilter(min_nnz=25),\n",
    "    XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, silent=0)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Again more complicated\n",
    "------------------\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from ooo_classifier.pipeline.map_transformer import MapTransformer\n",
    "from ooo_classifier.pipeline.text_analytics import (afinn, cut_beginning, stem,\n",
    "                                                    textblob_sentiment_polarity)\n",
    "\n",
    "\n",
    "def create_pipeline():\n",
    "    pipeline = make_pipeline(\n",
    "        make_union(\n",
    "            # beginning of the message sentiment\n",
    "            make_pipeline(\n",
    "                MapTransformer(func=lambda x: x[:100], n_jobs=-1, reshape_2d=False),\n",
    "                make_union(\n",
    "                    make_pipeline(MapTransformer(func=textblob_sentiment_polarity, reshape_2d=True, n_jobs=-1), Normalizer()),\n",
    "                    make_pipeline(MapTransformer(func=afinn, reshape_2d=True, n_jobs=-1), Normalizer())\n",
    "                )\n",
    "            ),\n",
    "\n",
    "            # beginning of the message bag of words\n",
    "            make_pipeline(\n",
    "                MapTransformer(func=stem, n_jobs=-1),\n",
    "                MapTransformer(func=cut_beginning, n_jobs=-1),\n",
    "                make_union(\n",
    "                    TfidfVectorizer(min_df=5, ngram_range=(1, 3), binary=True),\n",
    "                    TfidfVectorizer(min_df=5, analyzer=\"char_wb\", ngram_range=(1, 4), binary=True),\n",
    "                )\n",
    "            ),\n",
    "\n",
    "            # whole message bag of words\n",
    "            make_pipeline(\n",
    "                MapTransformer(func=stem, n_jobs=-1),\n",
    "                make_union(\n",
    "                    TfidfVectorizer(min_df=5, binary=True),\n",
    "                    TfidfVectorizer(min_df=5, analyzer=\"char_wb\", ngram_range=(1, 4), binary=True),\n",
    "                )\n",
    "            ),\n",
    "        ),\n",
    "        VotingClassifier([\n",
    "            ('mlp1', MLPClassifier(activation=\"tanh\", alpha=0.1, max_iter=100,\n",
    "                                   hidden_layer_sizes=(50,), verbose=False)),\n",
    "            ('xgb1', XGBClassifier(max_depth=3, n_estimators=200, min_child_weight=5)),\n",
    "        ], voting=\"soft\")\n",
    "    )\n",
    "    return pipeline\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. out of office classifier\n",
    "\n",
    "```python\n",
    "    pipeline = make_pipeline(\n",
    "\n",
    "        make_union(\n",
    "            make_pipeline(\n",
    "                PandasSelector(columns=[\"raw_data\"]),\n",
    "                EmailHeadersParse(columns=[\"subject\", \"content-type\", \"precedence\", \"auto-submitted\",\n",
    "                                           \"auto-response-suppress\", \"autoreply\", \"return-path\",\n",
    "                                           \"delivered-to\", \"auto-response-suppress\", \"ms-has-attach\",\n",
    "                                           \"failed-recipients\", \"cc\", \"from\"]),\n",
    "                make_union(\n",
    "                    make_pipeline(\n",
    "                        PandasSelector(columns=[\"subject\"]),\n",
    "                        CountVectorizer(binary=True, min_df=5)\n",
    "                    ),\n",
    "                    make_pipeline(\n",
    "                        PandasSelector(columns=[\"content-type\"]),\n",
    "                        CountVectorizer(binary=True, min_df=5)\n",
    "                    ),\n",
    "                    make_pipeline(\n",
    "                        PandasSelector(columns=[\"precedence\"]),\n",
    "                        CountVectorizer(binary=True, min_df=5)\n",
    "                    ),\n",
    "                    make_pipeline(\n",
    "                        PandasSelector(columns=[\"auto-submitted\"]),\n",
    "                        CountVectorizer(binary=True, min_df=5)\n",
    "                    ),\n",
    "                    make_pipeline(\n",
    "                        PandasSelector(columns=[\"auto-response-suppress\"]),\n",
    "                        CountVectorizer(binary=True, min_df=5)\n",
    "                    ),\n",
    "                    make_pipeline(\n",
    "                        PandasSelector(columns=[\"autoreply\"]),\n",
    "                        CountVectorizer(binary=True, min_df=5)\n",
    "                    ),\n",
    "                    make_pipeline(\n",
    "                        PandasSelector(columns=[\"return-path\"]),\n",
    "                        MapTransformer(return_path_transform, reshape_2d=True)\n",
    "                    ),\n",
    "                    make_pipeline(\n",
    "                        PandasSelector(columns=[\"delivered-to\"]),\n",
    "                        CountVectorizer(binary=True, min_df=5)\n",
    "                    ),\n",
    "                    make_pipeline(\n",
    "                        PandasSelector(columns=[\"auto-response-suppress\"]),\n",
    "                        CountVectorizer(binary=True, min_df=5)\n",
    "                    ),\n",
    "                    make_pipeline(\n",
    "                        PandasSelector(columns=[\"ms-has-attach\"]),\n",
    "                        CountVectorizer(binary=True, min_df=5)\n",
    "                    ),\n",
    "                    make_pipeline(\n",
    "                        PandasSelector(columns=[\"failed-recipients\"]),\n",
    "                        MapTransformer(len, reshape_2d=True)\n",
    "                    ),\n",
    "                    make_pipeline(\n",
    "                        PandasSelector(columns=[\"cc\"]),\n",
    "                        MapTransformer(len, reshape_2d=True)\n",
    "                    ),\n",
    "                    make_pipeline(\n",
    "                        PandasSelector(columns=[\"from\"]),\n",
    "                        CountVectorizer(binary=True, min_df=10)\n",
    "                    ),\n",
    "                )\n",
    "            ),\n",
    "\n",
    "            make_pipeline(\n",
    "                PandasSelector(columns=[\"raw_data\"]),\n",
    "                CountVectorizer(binary=True, min_df=5)\n",
    "            ),\n",
    "\n",
    "            make_pipeline(\n",
    "                PandasSelector(columns=[\"message_body_plain\"]),\n",
    "\n",
    "                make_union(\n",
    "                    # beginning of the message sentiment\n",
    "                    make_pipeline(\n",
    "                        MapTransformer(func=cut_beginning, n_jobs=-1, reshape_2d=False),\n",
    "                        make_union(\n",
    "                            MapTransformer(func=textblob_sentiment_polarity, reshape_2d=True, n_jobs=-1),\n",
    "                            MapTransformer(func=afinn, reshape_2d=True, n_jobs=-1)\n",
    "                        )\n",
    "                    ),\n",
    "\n",
    "                    # beginning of the message bag of words\n",
    "                    make_pipeline(\n",
    "                        MapTransformer(func=stem, n_jobs=-1),\n",
    "                        MapTransformer(func=cut_beginning, n_jobs=-1),\n",
    "                        make_union(\n",
    "                            CountVectorizer(min_df=5, ngram_range=(1, 2), binary=True),\n",
    "                            CountVectorizer(min_df=5, analyzer=\"char_wb\", ngram_range=(1, 2), binary=True),\n",
    "                        )\n",
    "                    ),\n",
    "\n",
    "                    # whole message bag of words\n",
    "                    make_pipeline(\n",
    "                        MapTransformer(func=stem, n_jobs=-1),\n",
    "                        make_union(\n",
    "                            CountVectorizer(min_df=5, binary=True),\n",
    "                            CountVectorizer(min_df=5, analyzer=\"char_wb\", ngram_range=(1, 2), binary=True),\n",
    "                        )\n",
    "                    )\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "        StandardScaler(with_mean=False),\n",
    "        ReportShape(),\n",
    "        est\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Growbots Recruitment challenge\n",
    "\n",
    "https://github.com/GSzpak/recruitment-challenge\n",
    "\n",
    "Especially this fragment\n",
    "\n",
    "https://github.com/GSzpak/recruitment-challenge/blob/master/src/json_transformer/run_transform_jsons.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
